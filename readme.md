**ML задача по классификации и кластеризации трафика**



**Решение состоит из трех частей:**

1) EDA анализ (вся информация по данным в ноутбуке)

   В файле 01_eda.ipynb

2) Процесс обучения моделей

   В файлах 01_eda.ipynb, 02_ds_clustering.ipynb, 03_ds_traffic_kmeans.ipynb

3) Инференс часть в виде Docker контейнера и FastAPI серверного приложения



**Основная суть и ход решения задачи:**

1) Выполнен минимальный препроцессинг данных
   1) Числовые значения - сохранены
   2) USER_AGENT - переводен в INT формат, путем кластеризации с использованием TFIDF и кластеризации
   3) Данные - превращены в эмббединги с помощью нейронной сети
2) Добавлено несколько дополнительных признаков
   1) Валидность колонок RESPONSE_CODE, MATCHED_VARIABLE_SRC
   2) Выделен признак страна из IP адреса
3) Полученные данные кластеризованы методом DBSCAN. Метод мной использовался, чтобы отделить обычный трафик от аномального. Все кластера с меткой -1, выделены как аномальные. Таким образом получены две метки 1 - трафик аномальный, 0 - обычный траифк.
4) На базе полученных меток обучена модель CatBoostClassifier
5) Далее для аномального трафика проведена кластеризация на 30 классов.



В результатате работы inference части, весь траифк кластеризуется на следующие кластеры:

	1) 0 = ошибка в IP адресе
	1) 1 = Обычный трафик
	1) 2-32 - отдельный кластер аномального трафика



В последствии предполагается, что Эксперт по безопасности должен проанализировать каждый кластер 2-32 на предмет, возможных уязвимостей, и дать описание каждому кластеру.



**Вывод:**

Решение является работоспособным! т.е. Все модели обучены. Часть inference работает, классы кластера трафику присваиваются.

Текущее решение, нельзя назвать полностью готовым, скорее это некое базовое решение, которое требует дальнейшего исследования, и дальнейшего совершествования.



По всем вопросам, или если что то не получается запустить, можно писать в телеграм @utrobinmv



**Что я не успел сделать:**

1) Поиграться с преобразованием признаков. OneHotEncoding, Scaller.
2) Проанализировать какие признаки дают больший вклад в каждый кластер.
3) Генерация новых признаков, например из данных.
4) Я не знаком с сетками, которые классифицируют данные трафика, поэтому взял самую простую и быструю сетку 'cointegrated/rubert-tiny2', для построения эмбеддингов строковых и байтовых данных.
5)  pytest
6) Подбор гиперпараметров, для получения лучших результатов и лучших метрик
6) Визуализировать полученные кластера, например для USER AGENT (чтобы их охарактеризовать)
6) Допричесать код





**Для запуска** Docker:

```
git clone репозиторий
cd pt_homework_github
docker-compose up --build
```

Для запуска ноутбуков:

в браузере 127.0.0.1:18904

Для теста:

```
bash ./request.sh
output:
["{\"EVENT_ID\": \"AVdhXFgVq1Ppo9zF5Fxu\", \"LABEL_PRED\": 26}","{\"EVENT_ID\": \"AVdcJmIIq1Ppo9zF2YIp\", \"LABEL_PRED\": 1}"]
```



